
M. Abadi, et al. 
 TensorFlow: Large-Scale Machine Learning on Heterogeneous Systems,
  2015.

R. Acciarri et al.
 Convolutional neural networks applied to neutrino events in a liquid
  argon time projection chamber.
  Journal of Instrumentation, 12(3), 2017.

A. Aurisano, A. Radovic, D. Rocco, A. Himmel, M. D. Messier, E. Niner,
  G. Pawloski, F. Psihas, A. Sousa, and P. Vahle.
 A convolutional neural network neutrino event classifier.
  Journal of Instrumentation, 11(9), 2016.

G. Bellec, D. Salaj, A. Subramoney, R. Legenstein, and W. Maass.
 Long short-term memory and learning-to-learn in networks of spiking
  neurons.
 In  Advances in Neural Information Processing Systems, pages
  787--797, 2018.

C. Blundell, J. Cornebise, K. Kavukcuoglu, and D. Wierstra.
 Weight Uncertainty in Neural Networks.
 may 2015.

S. Dieleman, K. W. Willett, and J. Dambre.
 Rotation-invariant convolutional neural networks for galaxy
  morphology prediction.
  Monthly Notices of the Royal Astronomical Society,
  450(2):1441--1459, 2015.

L. Fussell and B. Moews.
 Forging new worlds: High-resolution synthetic galaxies with chained
  generative adversarial networks.
  Monthly Notices of the Royal Astronomical Society,
  485(3):3215--3223, 2019.

A. Graves.
 Practical Variational Inference for Neural Networks.
  Nips, pages 1--9, 2011.

C. Guo, G. Pleiss, Y. Sun, and K. Q. Weinberger.
 On Calibration of Modern Neural Networks.
 In D. Precup and Y. W. Teh, editors,  Proceedings of the 34th
  International Conference on Machine Learning, volume 70 of  Proceedings
  of Machine Learning Research, pages 1321--1330, International Convention
  Centre, Sydney, Australia, aug 2017. PMLR.

Y. Kim, C. Yang, Y. Kim, G. X. Gu, and S. Ryu.
 Designing an Adhesive Pillar Shape with Deep Learning-Based
  Optimization.
  ACS Applied Materials and Interfaces, 12(21):24458--24465, may
  2020.

T. Kraska, A. Beutel, E. H. Chi, J. Dean, and N. Polyzotis.
 The Case for Learned Index Structures.
 In  Proceedings of the 2018 International Conference on
  Management of Data, SIGMOD '18, pages 489--504, New York, NY, USA, 2018.
  Association for Computing Machinery.

J. Kwon and L. P. Carloni.
 Transfer learning for design-space exploration with high-level
  synthesis.
 In  MLCAD 2020 - Proceedings of the 2020 ACM/IEEE Workshop on
  Machine Learning for CAD, 2020.

F. Lanusse, P. Melchior, and F. Moolekamp.
 Hybrid physical-deep learning model for astronomical inverse
  problems.
  arXiv, 2019.

G. Li, X. Zhou, S. Li, and B. Gao.
 QTune: A Query-Aware Database Tuning System with Deep Reinforcement
  Learning.
  Proceedings of the VLDB Endowment, 12(12):2118--2130, aug 2019.

H. Liu, M. Xu, Z. Yu, V. Corvinelli, and C. Zuzarte.
 Cardinality Estimation Using Neural Networks.
 In  Proceedings of the 25th Annual International Conference on
  Computer Science and Software Engineering, CASCON '15, pages 53--59, USA,
  2015. IBM Corp.

Q. Liu and D. Wang.
 Stein Variational Gradient Descent: A General Purpose Bayesian
  Inference Algorithm.
 In D. D. Lee, M. Sugiyama, U. V. Luxburg, I. Guyon, and R. Garnett,
  editors,  Advances in Neural Information Processing Systems 29, pages
  2378--2386. Curran Associates, Inc., 2016.

Y. C. Lu, S. S. Kiran Pentapati, L. Zhu, K. Samadi, and S. K. Lim.
 TP-GNN: A graph neural network framework for tier partitioning in
  monolithic 3D ICs.
 In  Proceedings - Design Automation Conference, 2020.

R. Marcus and O. Papaemmanouil.
 Plan-Structured Deep Neural Network Models for Query Performance
  Prediction.
 In  Proceedings of the VLDB Endowment, volume 12, pages
  1733--1746, 2019.

R. M. Neal.
  Bayesian Learning for Neural Networks (Lecture Notes in
  Statistics).
 Springer, 1 edition, aug 1996.

R. M. Neal.
 MCMC using Hamiltonian dynamics.
 in Handbook of Markov Chain Monte Carlo (eds S. Brooks, A. Gelman, G.
  Jones, XL Meng). Chapman and Hall/CRC Press, 2010.

K. Osawa, S. Swaroop, M. E. E. Khan, A. Jain, R. Eschenhagen, R. E. Turner, and
  R. Yokota.
 Practical Deep Learning with Bayesian Principles.
 In  Advances in Neural Information Processing Systems 32, pages
  4287--4299. Curran Associates, Inc., 2019.

Y. Ovadia, E. Fertig, J. Ren, Z. Nado, D. Sculley, S. Nowozin, J. Dillon,
  B. Lakshminarayanan, and J. Snoek.
 Can you trust your model's uncertainty? Evaluating predictive
  uncertainty under dataset shift.
 In  Advances in Neural Information Processing Systems,
  volume 32, pages 13991--14002. Curran Associates, Inc., 2019.

A. Paszke, S. Gross, F. Massa, A. Lerer, J. Bradbury, G. Chanan, T. Killeen,
  Z. Lin, N. Gimelshein, L. Antiga, A. Desmaison, A. Kopf, E. Yang, Z. DeVito,
  M. Raison, A. Tejani, S. Chilamkurthy, B. Steiner, L. Fang, J. Bai, and
  S. Chintala.
 PyTorch: An Imperative Style, High-Performance Deep Learning
  Library.
 In  Advances in Neural Information Processing Systems,
  volume 32, pages 8026--8037. Curran Associates, Inc., 2019.

D. Rezende and S. Mohamed.
 Variational Inference with Normalizing Flows.
 In  Proceedings of the 32nd International Conference on Machine
  Learning, volume 37 of  Proceedings of Machine Learning Research, pages
  1530--1538, Lille, France, 2015. PMLR.

B. H. Tran, S. Rossi, D. Milios, and M. Filippone.
 All you need is a good functional prior for Bayesian deep learning,
  2020.

J. X. Wang, Z. Kurth-Nelson, D. Kumaran, D. Tirumala, H. Soyer, J. Z. Leibo,
  D. Hassabis, and M. Botvinick.
 Prefrontal cortex as a meta-reinforcement learning system.
  Nature Neuroscience, 21(6):860--868, 2018.

F. Wenzel, K. Roth, B. S. Veeling, J. \'Swi\catkowski, L. Tran,
  S. Mandt, J. Snoek, T. Salimans, R. Jenatton, and S. Nowozin.
 How good is the Bayes posterior in deep neural networks really?
 In  arXiv, 2020.

A. G. Wilson.
 The case for Bayesian deep learning.
  arXiv preprint arXiv:2001.10995, 2020.

J. K. Wilt, C. Yang, and G. X. Gu.
 Accelerating Auxetic Metamaterial Design with Deep Learning.
  Advanced Engineering Materials, 22(5):1901266, may 2020.

D. L. Yamins and J. J. DiCarlo.
 Using goal-driven deep learning models to understand sensory
  cortex.
 In  Nature Neuroscience, volume 19, pages 356--365, 2016.

A. M. Zador.
 A critique of pure learning and what artificial neural networks can
  learn from animal brains.
 In  Nature Communications, volume 10, 2019.

F. Zhang, B. Shao, G. Xu, B. Yang, Z. Yang, Z. Qin, K. Ren, and Z. Yang.
 From homogeneous to heterogeneous: Leveraging deep learning based
  power analysis across devices.
 In  Proceedings - Design Automation Conference, 2020.

G. Zhang, S. Sun, D. Duvenaud, and R. Grosse.
 Noisy Natural Gradient as Variational Inference.
 In J. Dy and A. Krause, editors,  Proceedings of the 35th
  International Conference on Machine Learning, volume 80 of  Proceedings
  of Machine Learning Research, pages 5852--5861,
  Stockholm Sweden, 2018. PMLR.

Z. Zhang and G. X. Gu.
 Finite-Element-Based Deep-Learning Model for Deformation Behavior of
  Digital Materials.
  Advanced Theory and Simulations, 3(7):2000031, jul 2020.

G. X. G. Zhizhou Zhang.
 Physics-informed deep learning for digital materials.
  Theoretical & Applied Mechanics Letters, 11:1, 2021.

